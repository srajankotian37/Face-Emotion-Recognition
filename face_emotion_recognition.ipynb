{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImageTK' from 'PIL' (c:\\Users\\sraja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtkinter\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtk\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepFace\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageTK\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Create the main GUI windowpip install opencv-python\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ImageTK' from 'PIL' (c:\\Users\\sraja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from deepface import DeepFace\n",
    "from PIL import Image, ImageTk\n",
    "import random\n",
    "\n",
    "# Create the main GUI windowpip install opencv-python\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "root.geometry(\"800x600\")  # Set the window geometry\n",
    "root.title(\"Face Emotion Recognition\")\n",
    "\n",
    "# Create a frame to hold the camera feed label with padding\n",
    "outer_frame = tk.Frame(root, bg=\"black\")\n",
    "outer_frame.pack(pady=20, padx=(80, 80), expand=tk.YES, fill=tk.BOTH)  # Center and add padding\n",
    "\n",
    "# Create a label to display video feed\n",
    "video_label = tk.Label(outer_frame, bg=\"white\")\n",
    "video_label.pack(expand=tk.YES, fill=tk.BOTH)\n",
    "\n",
    "# Create a label to display emotion quotes\n",
    "quote_label = tk.Label(root, text=\"\", font=(\"Helvetica\", 20))\n",
    "quote_label.pack()\n",
    "\n",
    "# Emotion-quote dictionary\n",
    "emotion_quotes = {\n",
    "    \"angry\": \"Stay calm and keep moving forward.\",\n",
    "    \"happy\": \"Happiness is a choice. Choose it.\",\n",
    "    \"sad\": \"Every cloud has a silver lining.\",\n",
    "    \"neutral\": \"Sometimes, no emotion is the best emotion.\",\n",
    "    \"surprise\": \"Life is full of surprises. Embrace them.\",\n",
    "    \"fear\": \"Fear is temporary; regret is forever.\"\n",
    "}\n",
    "\n",
    "# Function to start webcam capture and analysis\n",
    "def start_capture():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot Open Webcam\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        resized_frame = cv2.resize(frame, (224, 224))\n",
    "        result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        dominant_emotion = result[0]['dominant_emotion']\n",
    "        quote = emotion_quotes.get(dominant_emotion.lower(), \"No quote available.\")\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame, dominant_emotion, (50, 100), font, 3, (0, 0, 255), 2, cv2.LINE_4)\n",
    "\n",
    "        # Convert OpenCV frame to Tkinter format\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(img)\n",
    "        img = ImageTk.PhotoImage(image=img)\n",
    "\n",
    "        video_label.imgtk = img\n",
    "        video_label.config(image=img)\n",
    "\n",
    "        quote_label.config(text=quote)  # Update emotion quote in the GUI\n",
    "\n",
    "        root.update()  # Update the GUI window\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('t'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Frame to hold buttons\n",
    "button_frame = tk.Frame(root)\n",
    "button_frame.pack(pady=20)\n",
    "\n",
    "# Start button\n",
    "start_button = tk.Button(button_frame, text=\"Start\", command=start_capture, bg=\"green\", fg=\"white\", font=(\"Helvetica\", 20))\n",
    "start_button.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "# Quit button\n",
    "quit_button = tk.Button(button_frame, text=\"Quit\", command=root.destroy, bg=\"red\", fg=\"white\", font=(\"Helvetica\", 20))\n",
    "quit_button.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "# Create the cascade classifier outside the function\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Start the GUI event loop\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
